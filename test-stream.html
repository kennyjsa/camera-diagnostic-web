<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Teste de Stream de V√≠deo</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" />
  <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.5/font/bootstrap-icons.css" rel="stylesheet" />
  <style>
    body {
      background-color: #f8f9fa;
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    .video-container {
      position: relative;
      max-width: 100%;
      margin: 20px 0;
    }
    #videoElement {
      width: 100%;
      max-width: 640px;
      height: auto;
      border: 2px solid #007bff;
      border-radius: 8px;
    }
    .controls {
      margin: 20px 0;
      padding: 15px;
      background: #fff;
      border-radius: 8px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .terminal {
      background: rgb(33, 37, 41);
      color: #0f0;
      padding: 1rem;
      height: 400px;
      overflow-y: auto;
      white-space: pre-wrap;
      border-bottom-left-radius: 5px;
      border-bottom-right-radius: 5px;
      font-family: monospace;
      font-size: 0.875rem;
    }
    .log {
      background: #f8f9fa;
      border: 1px solid #dee2e6;
      border-radius: 5px;
      padding: 15px;
      height: 200px;
      overflow-y: auto;
      font-family: monospace;
      font-size: 0.875rem;
      white-space: pre-wrap;
    }
    .capability-item {
      background: #e9ecef;
      padding: 8px 12px;
      margin: 5px 0;
      border-radius: 4px;
      font-size: 0.875rem;
    }
    .error {
      color: #dc3545;
    }
    .success {
      color: #28a745;
    }
    .info {
      color: #17a2b8;
    }
    
    .hidden {
      display: none;
    }
    
    .btn-success {
      background-color: #28a745;
      border-color: #28a745;
    }
    
    .btn-success:hover {
      background-color: #218838;
      border-color: #1e7e34;
    }
  </style>
</head>
<body>

<div class="container py-5">
  <div class="text-center mb-4">
    <h1><i class="bi bi-camera-video-fill"></i> Teste de Stream de V√≠deo</h1>
    <p class="text-muted">Teste a funcionalidade de sele√ß√£o e configura√ß√£o de c√¢mera</p>
  </div>

  <div class="row">
    <div class="col-12">
      <div class="video-container">
        <video id="videoElement" autoplay muted playsinline></video>
      </div>
      
      <div class="controls">
        <div class="row">
          <div class="col-md-6">
            <h5>Configura√ß√µes de C√¢mera</h5>
            <div class="mb-3">
              <label class="form-label">Facing Mode:</label>
              <select id="facingMode" class="form-select">
                <option value="environment">Environment (Traseira)</option>
                <option value="user">User (Frontal)</option>
              </select>
            </div>
            <div class="d-grid gap-2">
              <button class="btn btn-primary" onclick="startStream()">
                <i class="bi bi-camera-video-fill"></i> Iniciar Stream
              </button>
              <button class="btn btn-danger" onclick="stopStream()">
                <i class="bi bi-stop-circle"></i> Parar Stream
              </button>
              <button class="btn btn-secondary" onclick="clearLog()">
                <i class="bi bi-trash"></i> Limpar Log
              </button>
              <button class="btn btn-success" onclick="enviarDiagnostico()" id="enviarBtn" style="display:none">
                <i class="bi bi-clipboard-check"></i> Enviar Diagn√≥stico
              </button>
            </div>
          </div>
          
          <div class="col-md-6">
            <h5>Capacidades Detectadas</h5>
            <div id="capabilities"></div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- Terminal de Diagn√≥stico -->
  <div class="card shadow-sm mb-3 mt-4">
    <div class="card-header bg-dark text-white">
      <i class="bi bi-terminal"></i> Terminal de Diagn√≥stico - Log Detalhado
    </div>
    <div class="terminal" id="diagnosticLog">üü¢ Aguardando in√≠cio do diagn√≥stico...</div>
  </div>

  <!-- Formul√°rio de Diagn√≥stico -->
  <form name="diagnostico" method="POST" action="/thankyou.html" netlify-honeypot="bot-field" data-netlify="true">
    <p class="hidden">
      <label>
        Don't fill this out if you're human: <input name="bot-field" type="text" />
      </label>
    </p>
    <input type="hidden" name="form-name" value="diagnostico" />
    <input type="hidden" name="debugId" />
    <input type="hidden" name="deviceDate" />
    <input type="hidden" name="elapsedTimeMs" />
    <input type="hidden" name="browserName" />
    <input type="hidden" name="browserVersion" />
    <input type="hidden" name="os" />
    <input type="hidden" name="language" />
    <input type="hidden" name="cameraCount" />
    <input type="hidden" name="supportsMediaDevices" />
    <input type="hidden" name="permissionsCamera" />
    <input type="hidden" name="permissionsMicrophone" />
    <input type="hidden" name="cameraInfo" />
    <input type="hidden" name="errors" />
    <input type="hidden" name="streamTestResults" />
    <input type="hidden" name="selectedDeviceId" />
    <input type="hidden" name="facingMode" />
    <input type="hidden" name="capabilitiesDetected" />
    <input type="hidden" name="diagnosticLog" />
    <input type="hidden" name="diagnosticLogText" />
  </form>
</div>

<script>
// Cache para deviceId por facingMode
const cachedDeviceIdMap = {};

// Tipos TypeScript (convertidos para JSDoc)
/**
 * @typedef {Object} ZoomCapabilities
 * @property {number} min
 * @property {number} max
 * @property {number} step
 * @property {number} current
 */

/**
 * @typedef {Object} VideoStreamConfig
 * @property {MediaStream} stream
 * @property {string} [deviceId]
 * @property {ZoomCapabilities|null} zoomCaps
 * @property {boolean} torchSupported
 * @property {string[]} [focusModes]
 * @property {string[]} [whiteBalanceModes]
 * @property {boolean} pointsOfInterestSupported
 */

let diagnosticLogEl, videoEl, capabilitiesEl;

const log = (text, type = 'info') => {
  if (!diagnosticLogEl) {
    console.error('diagnosticLogEl n√£o est√° dispon√≠vel');
    return;
  }
  const timestamp = new Date().toLocaleTimeString();
  const className = type === 'error' ? 'error' : type === 'success' ? 'success' : 'info';
  diagnosticLogEl.innerHTML += `<span class="${className}">[${timestamp}] ${text}</span>\n`;
  diagnosticLogEl.scrollTop = diagnosticLogEl.scrollHeight;
};

// Fun√ß√£o para inicializar os elementos
function initializeElements() {
  diagnosticLogEl = document.getElementById('diagnosticLog');
  videoEl = document.getElementById('videoElement');
  capabilitiesEl = document.getElementById('capabilities');
  
  if (!diagnosticLogEl) {
    console.error('Elemento diagnosticLog n√£o encontrado');
  }
  if (!videoEl) {
    console.error('Elemento videoElement n√£o encontrado');
  }
  if (!capabilitiesEl) {
    console.error('Elemento capabilities n√£o encontrado');
  }
}

let currentStream = null;
let startTime;
let diagnosticData = {
  streamTestResults: null,
  selectedDeviceId: null,
  facingMode: null,
  capabilitiesDetected: null,
  errors: []
};

/**
 * Seleciona c√¢mera baseada nas capacidades
 * @param {MediaDeviceInfo[]} inputs
 * @param {'user' | 'environment'} facingMode
 * @returns {Promise<string|undefined>}
 */
async function selectCameraByCapabilities(
  inputs,
  facingMode
) {
  log(`üîç INICIANDO SELE√á√ÉO DE C√ÇMERA`);
  log(`üìã Par√¢metros: facingMode=${facingMode}, totalDevices=${inputs.length}`);
  
  const candidates = [];

  for (let i = 0; i < inputs.length; i++) {
    const device = inputs[i];
    let stream = null;
    
    log(`\nüì∑ TESTANDO DISPOSITIVO ${i + 1}/${inputs.length}`);
    log(`   DeviceId: ${device.deviceId}`);
    log(`   Label: ${device.label || 'Sem label'}`);
    log(`   GroupId: ${device.groupId || 'Sem groupId'}`);
    
    try {
      log(`   üîÑ Abrindo stream de teste...`);
      
      // Abre stream curto para avaliar capabilities
      stream = await navigator.mediaDevices.getUserMedia({
        video: { deviceId: { exact: device.deviceId } },
        audio: false,
      });
      
      log(`   ‚úÖ Stream aberto com sucesso`);
      
      const track = stream.getVideoTracks()[0];
      log(`   üìπ Track obtida: ${track.label}`);
      
      const caps = track.getCapabilities() || {};
      log(`   üîß Capabilities obtidas: ${Object.keys(caps).length} propriedades`);
      
      // Log detalhado de todas as capabilities
      for (const [key, value] of Object.entries(caps)) {
        if (Array.isArray(value)) {
          log(`   üìã ${key}: [${value.join(', ')}]`);
        } else if (typeof value === 'object' && value !== null) {
          log(`   üìã ${key}: ${JSON.stringify(value)}`);
        } else {
          log(`   üìã ${key}: ${value}`);
        }
      }
      
      let score = 0;
      log(`   üéØ Iniciando avalia√ß√£o de score...`);

      // Verifica facingMode
      if (!Array.isArray(caps.facingMode)) {
        log(`   ‚ùå facingMode n√£o √© array: ${typeof caps.facingMode}`);
        track.stop();
        continue;
      }
      
      if (!caps.facingMode.includes(facingMode)) {
        log(`   ‚ùå facingMode '${facingMode}' n√£o suportado. Dispon√≠veis: [${caps.facingMode.join(', ')}]`);
        track.stop();
        continue;
      }
      
      log(`   ‚úÖ facingMode '${facingMode}' suportado`);

      // Avalia zoom
      if (caps.zoom) {
        score += 1;
        log(`   ‚úÖ Zoom detectado: min=${caps.zoom.min}, max=${caps.zoom.max}, step=${caps.zoom.step} (+1 ponto)`);
      } else {
        log(`   ‚ùå Zoom n√£o dispon√≠vel`);
      }
      
      // Avalia focus mode
      if (Array.isArray(caps.focusMode)) {
        log(`   üìã Focus modes dispon√≠veis: [${caps.focusMode.join(', ')}]`);
        if (caps.focusMode.includes('continuous')) {
          score += 5;
          log(`   ‚úÖ Foco cont√≠nuo detectado (+5 pontos)`);
        } else {
          log(`   ‚ùå Foco cont√≠nuo n√£o dispon√≠vel`);
        }
      } else {
        log(`   ‚ùå Focus modes n√£o dispon√≠vel`);
      }
      
      // Avalia white balance
      if (Array.isArray(caps.whiteBalanceMode)) {
        log(`   üìã White balance modes dispon√≠veis: [${caps.whiteBalanceMode.join(', ')}]`);
        if (caps.whiteBalanceMode.includes('continuous')) {
          score += 1;
          log(`   ‚úÖ White balance cont√≠nuo detectado (+1 ponto)`);
        } else {
          log(`   ‚ùå White balance cont√≠nuo n√£o dispon√≠vel`);
        }
      } else {
        log(`   ‚ùå White balance modes n√£o dispon√≠vel`);
      }
      
      // Avalia points of interest
      if (Array.isArray(caps.pointsOfInterest)) {
        score += 1;
        log(`   ‚úÖ Points of interest detectado: ${caps.pointsOfInterest.length} pontos (+1 ponto)`);
      } else {
        log(`   ‚ùå Points of interest n√£o dispon√≠vel`);
      }

      // Avalia zoom m√≠nimo
      if (caps.zoom?.min === 1) {
        score += 1;
        log(`   ‚úÖ Zoom m√≠nimo = 1 (+1 ponto)`);
      } else if (caps.zoom) {
        log(`   ‚ùå Zoom m√≠nimo = ${caps.zoom.min} (n√£o √© 1)`);
      }
      
      candidates.push({ deviceId: device.deviceId, score });
      log(`   üìä SCORE FINAL: ${score} pontos`);
      track.stop();
      log(`   üõë Track parada`);
      
    } catch (error) {
      log(`   ‚ùå ERRO ao testar dispositivo: ${error.name}: ${error.message}`, 'error');
      log(`   üìã Stack trace: ${error.stack}`, 'error');
    } finally {
      try {
        if (stream) {
          stream.getTracks().forEach((t) => t.stop());
          log(`   üõë Stream limpo`);
        }
      } catch (error) {
        log(`   ‚ùå ERRO ao limpar stream: ${error.name}: ${error.message}`, 'error');
        log(`   üìã Stack trace: ${error.stack}`, 'error');
      }
    }
  }
  
  log(`\nüìä RESUMO DOS CANDIDATOS:`);
  candidates.forEach((candidate, index) => {
    log(`   ${index + 1}. DeviceId: ${candidate.deviceId} - Score: ${candidate.score}`);
  });
  
  // Ordena e retorna o deviceId de maior score
  candidates.sort((a, b) => b.score - a.score);
  
  if (candidates.length > 0) {
    log(`\nüèÜ MELHOR CANDIDATO SELECIONADO:`, 'success');
    log(`   DeviceId: ${candidates[0].deviceId}`, 'success');
    log(`   Score: ${candidates[0].score}`, 'success');
    return candidates[0].deviceId;
  }
  
  log(`\n‚ùå NENHUM DISPOSITIVO ADEQUADO ENCONTRADO`, 'error');
  return undefined;
}

/**
 * Inicia stream aplicando cache em mem√≥ria e facingMode na sele√ß√£o.
 * @param {'user' | 'environment'} facingMode
 * @returns {Promise<VideoStreamConfig>}
 */
async function startVideoStream(
  facingMode = 'environment'
) {
  log(`\nüöÄ INICIANDO STARTVIDEOSTREAM`);
  log(`üìã Par√¢metros: facingMode=${facingMode}`);
  
  try {
    log(`üîÑ Abrindo stream inicial com facingMode...`);
    let stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode },
      audio: false,
    });
    log(`‚úÖ Stream inicial aberto com sucesso`);

    log(`üîç Enumerando dispositivos...`);
    const devices = await navigator.mediaDevices.enumerateDevices();
    const videoInputs = devices.filter((d) => d.kind === 'videoinput');

    log(`üì± Dispositivos encontrados:`);
    log(`   Total: ${devices.length}`);
    log(`   V√≠deo: ${videoInputs.length}`);
    log(`   √Åudio: ${devices.filter(d => d.kind === 'audioinput').length}`);
    log(`   √Åudio output: ${devices.filter(d => d.kind === 'audiooutput').length}`);

    // Log detalhado de todos os dispositivos de v√≠deo
    videoInputs.forEach((device, index) => {
      log(`   üì∑ ${index + 1}. ${device.label || 'Sem label'} (${device.deviceId})`);
    });

    // Verifica cache
    let deviceId = cachedDeviceIdMap[facingMode];
    log(`üìã Verificando cache para facingMode '${facingMode}': ${deviceId || 'n√£o encontrado'}`);
    
    if (deviceId) {
      const cachedDevice = videoInputs.find((d) => d.deviceId === deviceId);
      if (cachedDevice) {
        log(`‚úÖ DeviceId cacheado ainda v√°lido: ${deviceId}`);
      } else {
        log(`‚ùå DeviceId cacheado n√£o encontrado nos dispositivos atuais`);
        deviceId = null;
      }
    }

    if (!deviceId) {
      log(`üîÑ Cache inv√°lido ou n√£o encontrado, iniciando sele√ß√£o de c√¢mera...`);
      deviceId = await selectCameraByCapabilities(videoInputs, facingMode);
      if (deviceId) {
        cachedDeviceIdMap[facingMode] = deviceId;
        log(`üíæ DeviceId cacheado para ${facingMode}: ${deviceId}`, 'success');
      } else {
        log(`‚ùå Nenhum deviceId selecionado`, 'error');
      }
    } else {
      log(`üìã Usando deviceId cacheado: ${deviceId}`);
    }

    if (!deviceId) {
      log(`‚ö†Ô∏è Usando stream padr√£o sem deviceId espec√≠fico`);
      return {
        stream,
        zoomCaps: null,
        torchSupported: false,
        pointsOfInterestSupported: false,
      };
    }

    // Abre stream final
    log(`üé¨ Abrindo stream final com deviceId espec√≠fico...`);
    log(`   DeviceId: ${deviceId}`);
    log(`   FacingMode: ${facingMode}`);
    
    try {
      stream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode,
          deviceId: { exact: deviceId },
        },
        audio: false,
      });
      log(`‚úÖ Stream final aberto com sucesso`);
    } catch (streamError) {
      log(`‚ùå ERRO ao abrir stream final com deviceId espec√≠fico: ${streamError.name}: ${streamError.message}`, 'error');
      log(`üîÑ Tentando fallback para stream padr√£o...`);
      
      // Fallback para stream padr√£o
      try {
        stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode },
          audio: false,
        });
        log(`‚úÖ Stream padr√£o aberto com sucesso como fallback`);
        
        // Limpa o cache do deviceId que falhou
        delete cachedDeviceIdMap[facingMode];
        log(`üóëÔ∏è Cache limpo para facingMode '${facingMode}' devido ao erro`);
        
        // Retorna configura√ß√£o b√°sica para stream padr√£o
        const track = stream.getVideoTracks()[0];
        const caps = track.getCapabilities() || {};
        
        const config = {
          stream,
          deviceId: null, // Indica que √© stream padr√£o
          zoomCaps: null,
          torchSupported: false,
          focusModes: Array.isArray(caps.focusMode) ? caps.focusMode : undefined,
          whiteBalanceModes: Array.isArray(caps.whiteBalanceMode) ? caps.whiteBalanceMode : undefined,
          pointsOfInterestSupported: Array.isArray(caps.pointsOfInterest),
        };
        
        log(`üìä Configura√ß√£o de fallback:`, 'success');
        log(`   DeviceId: null (stream padr√£o)`, 'success');
        log(`   Focus Modes: ${config.focusModes ? config.focusModes.join(', ') : 'N√£o suportado'}`, 'success');
        log(`   White Balance: ${config.whiteBalanceModes ? config.whiteBalanceModes.join(', ') : 'N√£o suportado'}`, 'success');
        
        return config;
        
      } catch (fallbackError) {
        log(`‚ùå ERRO CR√çTICO: Fallback tamb√©m falhou: ${fallbackError.name}: ${fallbackError.message}`, 'error');
        throw fallbackError;
      }
    }

    // Aplica configura√ß√µes iniciais de capabilities
    const track = stream.getVideoTracks()[0];
    log(`üìπ Track obtida: ${track.label}`);
    
    const caps = track.getCapabilities() || {};
    log(`üîß Capabilities finais obtidas: ${Object.keys(caps).length} propriedades`);
    
    // Log detalhado das capabilities finais
    for (const [key, value] of Object.entries(caps)) {
      if (Array.isArray(value)) {
        log(`   üìã ${key}: [${value.join(', ')}]`);
      } else if (typeof value === 'object' && value !== null) {
        log(`   üìã ${key}: ${JSON.stringify(value)}`);
      } else {
        log(`   üìã ${key}: ${value}`);
      }
    }
    
    log(`üîß Aplicando configura√ß√µes avan√ßadas...`);
    const advanced = [];
    
    if (caps.zoom) {
      advanced.push({ zoom: caps.zoom.min });
      log(`üîç Zoom configurado para: ${caps.zoom.min}`);
    }
    
    if (Array.isArray(caps.focusMode) && caps.focusMode.includes('continuous')) {
      advanced.push({ focusMode: 'continuous' });
      log(`üéØ Foco cont√≠nuo ativado`);
    }
    
    if (
      Array.isArray(caps.whiteBalanceMode) &&
      caps.whiteBalanceMode.includes('continuous')
    ) {
      advanced.push({ whiteBalanceMode: 'continuous' });
      log(`‚öñÔ∏è White balance cont√≠nuo ativado`);
    }

    const constraints = {
      advanced: advanced.length ? advanced : undefined,
      frameRate: caps.frameRate?.max,
    };
    
    log(`üìã Constraints aplicadas: ${JSON.stringify(constraints)}`);
    
    await track.applyConstraints(constraints);
    log(`‚úÖ Constraints aplicadas com sucesso`);

    const zoomCaps = caps.zoom
      ? {
          min: caps.zoom.min,
          max: caps.zoom.max,
          step: caps.zoom.step ?? 0.1,
          current: caps.zoom.min,
        }
      : null;

    const config = {
      stream,
      deviceId: caps.deviceId,
      zoomCaps,
      torchSupported: Boolean(caps.torch),
      focusModes: Array.isArray(caps.focusMode) ? caps.focusMode : undefined,
      whiteBalanceModes: Array.isArray(caps.whiteBalanceMode)
        ? caps.whiteBalanceMode
        : undefined,
      pointsOfInterestSupported: Array.isArray(caps.pointsOfInterest),
    };

    log(`\n‚úÖ STREAM INICIADO COM SUCESSO!`, 'success');
    log(`üìä Configura√ß√£o final:`, 'success');
    log(`   DeviceId: ${config.deviceId}`, 'success');
    log(`   Zoom: ${config.zoomCaps ? 'Suportado' : 'N√£o suportado'}`, 'success');
    log(`   Torch: ${config.torchSupported ? 'Suportado' : 'N√£o suportado'}`, 'success');
    log(`   Focus Modes: ${config.focusModes ? config.focusModes.join(', ') : 'N√£o suportado'}`, 'success');
    log(`   White Balance: ${config.whiteBalanceModes ? config.whiteBalanceModes.join(', ') : 'N√£o suportado'}`, 'success');
    log(`   Points of Interest: ${config.pointsOfInterestSupported ? 'Suportado' : 'N√£o suportado'}`, 'success');
    
    return config;
    
  } catch (error) {
    log(`‚ùå ERRO em startVideoStream: ${error.name}: ${error.message}`, 'error');
    log(`üìã Stack trace: ${error.stack}`, 'error');
    throw error;
  }
}

/**
 * Inicia o stream de v√≠deo
 */
async function startStream() {
  try {
    if (!videoEl) {
      console.error('Elemento videoElement n√£o est√° dispon√≠vel');
      return;
    }
    
    startTime = Date.now();
    const facingMode = document.getElementById('facingMode').value;
    diagnosticData.facingMode = facingMode;
    
    log(`\nüé• INICIANDO TESTE DE STREAM`);
    log(`üìã FacingMode selecionado: ${facingMode}`);
    
    const config = await startVideoStream(facingMode);
    
    // Conecta o stream ao elemento de v√≠deo
    videoEl.srcObject = config.stream;
    currentStream = config.stream;
    
    // Exibe as capacidades detectadas
    displayCapabilities(config);
    
    // Coleta dados do diagn√≥stico
    diagnosticData.streamTestResults = 'success';
    diagnosticData.selectedDeviceId = config.deviceId;
    diagnosticData.capabilitiesDetected = {
      zoomCaps: config.zoomCaps,
      torchSupported: config.torchSupported,
      focusModes: config.focusModes,
      whiteBalanceModes: config.whiteBalanceModes,
      pointsOfInterestSupported: config.pointsOfInterestSupported
    };
    
    log(`\nüé¨ STREAM CONECTADO AO ELEMENTO DE V√çDEO`, 'success');
    log(`üìπ Elemento de v√≠deo atualizado com sucesso`, 'success');
    log(`üìä Dados do diagn√≥stico coletados com sucesso`, 'success');
    
    // Mostra o bot√£o de enviar diagn√≥stico
    document.getElementById('enviarBtn').style.display = 'inline-block';
    
  } catch (error) {
    log(`‚ùå ERRO ao iniciar stream: ${error.name}: ${error.message}`, 'error');
    log(`üìã Stack trace: ${error.stack}`, 'error');
    
    diagnosticData.streamTestResults = 'error';
    diagnosticData.errors.push(`Stream error: ${error.name}: ${error.message}`);
    
    // Mostra o bot√£o de enviar diagn√≥stico mesmo com erro
    document.getElementById('enviarBtn').style.display = 'inline-block';
  }
}

/**
 * Para o stream de v√≠deo
 */
function stopStream() {
  if (!videoEl) {
    console.error('Elemento videoElement n√£o est√° dispon√≠vel');
    return;
  }
  
  if (currentStream) {
    log(`‚èπÔ∏è Parando stream...`);
    currentStream.getTracks().forEach(track => {
      log(`   üõë Parando track: ${track.label}`);
      track.stop();
    });
    currentStream = null;
    videoEl.srcObject = null;
    log(`‚úÖ Stream parado com sucesso`, 'success');
  } else {
    log(`‚ö†Ô∏è Nenhum stream ativo para parar`);
  }
}

/**
 * Limpa o log de diagn√≥stico
 */
function clearLog() {
  if (diagnosticLogEl) {
    diagnosticLogEl.innerHTML = 'üü¢ Log limpo. Clique em "Iniciar Stream" para testar.';
    log(`üßπ Log de diagn√≥stico limpo`);
  }
}

/**
 * Obt√©m o log completo como texto
 */
function getFullLogText() {
  if (!diagnosticLogEl) {
    return 'Log n√£o dispon√≠vel - Elemento diagnosticLogEl n√£o encontrado';
  }
  
  try {
    // Remove as tags HTML e mant√©m apenas o texto
    const tempDiv = document.createElement('div');
    tempDiv.innerHTML = diagnosticLogEl.innerHTML;
    const textContent = tempDiv.textContent || tempDiv.innerText || '';

    // Se n√£o conseguiu extrair texto, tenta innerHTML
    if (!textContent || textContent.trim() === '') {
      return diagnosticLogEl.innerHTML || 'Log vazio';
    }

    return textContent;
  } catch (error) {
    console.error('Erro ao extrair texto do log:', error);
    return `Erro ao extrair log: ${error.message}`;
  }
}

/**
 * Envia o diagn√≥stico via formul√°rio Netlify
 */
function enviarDiagnostico() {
  log(`\nüì§ Enviando diagn√≥stico...`);
  
  const form = document.forms['diagnostico'];
  const debugId = Date.now().toString();
  const deviceDate = new Date().toISOString();
  const elapsedTime = Date.now() - startTime;
  
  // Informa√ß√µes do navegador
  const ua = navigator.userAgent;
  const platform = navigator.platform;
  const language = navigator.language;
  const browserInfo = parseUserAgent(ua);
  
  // Captura todo o conte√∫do do log de diagn√≥stico
  const fullLogHTML = diagnosticLogEl ? diagnosticLogEl.innerHTML : 'Log n√£o dispon√≠vel';
  const fullLogText = getFullLogText();
  log(`üìã Capturando log completo (HTML: ${fullLogHTML.length} chars, Texto: ${fullLogText.length} chars)...`);
  
  // Adiciona informa√ß√µes de debug sobre o log
  log(`üìä Informa√ß√µes do log:`, 'info');
  log(`   Elemento diagnosticLogEl: ${diagnosticLogEl ? 'Encontrado' : 'N√£o encontrado'}`, 'info');
  log(`   Conte√∫do HTML: ${fullLogHTML.length} caracteres`, 'info');
  log(`   Conte√∫do texto: ${fullLogText.length} caracteres`, 'info');
  log(`   Linhas de log: ${fullLogText.split('\n').length}`, 'info');
  
  // Preenche o formul√°rio
  form.debugId.value = debugId;
  form.deviceDate.value = deviceDate;
  form.elapsedTimeMs.value = elapsedTime;
  form.browserName.value = browserInfo.name;
  form.browserVersion.value = browserInfo.version;
  form.os.value = platform;
  form.language.value = language;
  form.facingMode.value = diagnosticData.facingMode || '';
  form.selectedDeviceId.value = diagnosticData.selectedDeviceId || '';
  form.streamTestResults.value = diagnosticData.streamTestResults || '';
  form.capabilitiesDetected.value = JSON.stringify(diagnosticData.capabilitiesDetected || {});
  form.errors.value = JSON.stringify(diagnosticData.errors);
  form.diagnosticLog.value = fullLogHTML; // Envia o HTML completo com cores
  form.diagnosticLogText.value = fullLogText; // Envia o texto puro
  
  // Informa√ß√µes de dispositivos e permiss√µes
  form.supportsMediaDevices.value = !!navigator.mediaDevices?.getUserMedia;
  
  // Coleta informa√ß√µes de dispositivos e permiss√µes
  (async () => {
    try {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const cameras = devices.filter(d => d.kind === 'videoinput');
      form.cameraCount.value = cameras.length;
      
      // Informa√ß√µes de permiss√µes
      try {
        const [camPerm, micPerm] = await Promise.all([
          navigator.permissions.query({ name: 'camera' }),
          navigator.permissions.query({ name: 'microphone' })
        ]);
        form.permissionsCamera.value = camPerm.state;
        form.permissionsMicrophone.value = micPerm.state;
      } catch {
        form.permissionsCamera.value = 'unsupported';
        form.permissionsMicrophone.value = 'unsupported';
      }
      
      // Informa√ß√µes detalhadas das c√¢meras
      const cameraData = [];
      for (let i = 0; i < cameras.length; i++) {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ 
            video: { deviceId: cameras[i].deviceId } 
          });
          const track = stream.getVideoTracks()[0];
          const data = {
            deviceId: cameras[i].deviceId,
            label: cameras[i].label,
            capabilities: track.getCapabilities?.() || {},
            settings: track.getSettings?.() || {},
            constraints: track.getConstraints?.() || {},
          };
          stream.getTracks().forEach(t => t.stop());
          cameraData.push(data);
        } catch (e) {
          diagnosticData.errors.push(`Erro na c√¢mera ${i + 1}: ${e.message}`);
        }
      }
      form.cameraInfo.value = JSON.stringify(cameraData);
      
    } catch (e) {
      diagnosticData.errors.push(`Erro ao enumerar dispositivos: ${e.message}`);
    }
    
      // Atualiza o formul√°rio com os erros coletados
  form.errors.value = JSON.stringify(diagnosticData.errors);
  
  // Verifica se o log foi capturado corretamente
  if (fullLogHTML && fullLogHTML.length > 0) {
    log(`‚úÖ Log capturado com sucesso:`, 'success');
    log(`   HTML: ${fullLogHTML.length} caracteres`, 'success');
    log(`   Texto: ${fullLogText.length} caracteres`, 'success');
  } else {
    log(`‚ö†Ô∏è Log n√£o p√¥de ser capturado`, 'error');
  }
  
    // Captura final do log (incluindo os logs do processo de envio)
    const finalLogHTML = diagnosticLogEl ? diagnosticLogEl.innerHTML : 'Log n√£o dispon√≠vel';
    const finalLogText = getFullLogText();

    // Atualiza o formul√°rio com o log final
    form.diagnosticLog.value = finalLogHTML;
    form.diagnosticLogText.value = finalLogText;

    log(`üì§ Enviando formul√°rio com log final:`, 'success');
    log(`   HTML final: ${finalLogHTML.length} caracteres`, 'success');
    log(`   Texto final: ${finalLogText.length} caracteres`, 'success');
  
  // Envia o formul√°rio
  form.submit();
  })();
  
  // Feedback visual
  log(`‚úÖ Diagn√≥stico enviado com sucesso!`, 'success');
  log(`üîÑ Redirecionando para p√°gina de agradecimento...`);
  
  // Esconde os bot√µes
  document.getElementById('enviarBtn').style.display = 'none';
  
  // Redireciona ap√≥s 1 segundo
  setTimeout(() => {
    window.location.href = "/thankyou.html";
  }, 1000);
}

/**
 * Parse do User Agent para extrair informa√ß√µes do navegador
 */
function parseUserAgent(ua) {
  let name = "Desconhecido", version = "0";
  if (ua.includes("Chrome/")) {
    name = "Chrome";
    version = ua.split("Chrome/")[1].split(" ")[0];
  } else if (ua.includes("Firefox/")) {
    name = "Firefox";
    version = ua.split("Firefox/")[1];
  } else if (ua.includes("Safari/") && ua.includes("Version/")) {
    name = "Safari";
    version = ua.split("Version/")[1].split(" ")[0];
  } else if (ua.includes("Edg/")) {
    name = "Edge";
    version = ua.split("Edg/")[1];
  }
  return { name, version };
}

/**
 * Exibe as capacidades detectadas
 * @param {VideoStreamConfig} config
 */
function displayCapabilities(config) {
  if (!capabilitiesEl) {
    console.error('Elemento capabilities n√£o est√° dispon√≠vel');
    return;
  }
  
  let html = '';
  
  if (config.zoomCaps) {
    html += `<div class="capability-item">
      <strong>üîç Zoom:</strong> ${config.zoomCaps.min} - ${config.zoomCaps.max} (step: ${config.zoomCaps.step})
    </div>`;
  }
  
  if (config.focusModes) {
    html += `<div class="capability-item">
      <strong>üéØ Focus Modes:</strong> ${config.focusModes.join(', ')}
    </div>`;
  }
  
  if (config.whiteBalanceModes) {
    html += `<div class="capability-item">
      <strong>‚öñÔ∏è White Balance:</strong> ${config.whiteBalanceModes.join(', ')}
    </div>`;
  }
  
  html += `<div class="capability-item">
    <strong>üî¶ Torch:</strong> ${config.torchSupported ? '‚úÖ Suportado' : '‚ùå N√£o suportado'}
  </div>`;
  
  html += `<div class="capability-item">
    <strong>üéØ Points of Interest:</strong> ${config.pointsOfInterestSupported ? '‚úÖ Suportado' : '‚ùå N√£o suportado'}
  </div>`;
  
  capabilitiesEl.innerHTML = html;
}

// Limpa o log ao carregar a p√°gina
window.addEventListener('load', () => {
  initializeElements();
  
  if (diagnosticLogEl) {
    diagnosticLogEl.innerHTML = 'üü¢ P√°gina carregada. Clique em "Iniciar Stream" para testar.';
    log(`üöÄ P√ÅGINA DE TESTE CARREGADA`);
    log(`üìã Funcionalidades dispon√≠veis:`);
    log(`   ‚Ä¢ Sele√ß√£o inteligente de c√¢mera por capabilities`);
    log(`   ‚Ä¢ Cache de deviceId por facing mode`);
    log(`   ‚Ä¢ Log detalhado de todo o processo`);
    log(`   ‚Ä¢ Exibi√ß√£o de capacidades detectadas`);
    log(`   ‚Ä¢ Teste de diferentes facing modes`);
  }
});

// Limpa o stream quando a p√°gina √© fechada
window.addEventListener('beforeunload', () => {
  if (currentStream) {
    currentStream.getTracks().forEach(track => track.stop());
  }
});
</script>
</body>
</html> 